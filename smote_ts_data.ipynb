{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62eacf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d702994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940673dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7576839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "train_df = pd.read_csv('./train_data.csv')\n",
    "validation_df = pd.read_csv('./validation_data.csv')\n",
    "test_df = pd.read_csv('./test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "367405bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD SLIDING WINDOW\n",
    "# df - dataframe used\n",
    "# window_size - size of the sliding window, by default 11s if not mentioned otherwise\n",
    "# step_size - starting point for the current window given the previous, by default 5\n",
    "# feature_cols - features to be used in the sliding window\n",
    "def create_windows(dataset, window_size=11, step_size=5, feature_cols=['ACC_X', 'ACC_Y', 'ACC_Z']):\n",
    "    X = []\n",
    "    y = []\n",
    "    window = []\n",
    "\n",
    "    for person_id in dataset['PERSON_ID'].unique():\n",
    "        person_data = dataset[dataset['PERSON_ID'] == person_id]\n",
    "        feature_values = person_data[feature_cols].values\n",
    "        activity = person_data['ACTIVITY']\n",
    "\n",
    "        max_window_end = len(person_data)\n",
    "\n",
    "        for i in range(0, max_window_end - window_size, step_size):\n",
    "            window = feature_values[i:i+window_size]\n",
    "            window_label = activity[i:i+window_size].mode(dropna=False).iloc[0]\n",
    "\n",
    "            # Ensure the window is of the correct size\n",
    "            if len(window) != window_size:\n",
    "                continue  # Skip this window if it's the wrong shape\n",
    "\n",
    "            X.append(window)\n",
    "            y.append(window_label)\n",
    "\n",
    "    print(len(X))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddfb7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 180\n",
    "step_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4637b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_windows(train_df, window_size, step_size)\n",
    "X_val, y_val = create_windows(validation_df, window_size, step_size)\n",
    "X_test, y_test = create_windows(test_df, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f06d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of windows per class to see the imbalance ratio among windows\n",
    "def print_window_distribution(y_labels):\n",
    "    class_counts = Counter(y_labels)\n",
    "    sorted_counts = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Window count per class (descending):\")\n",
    "    for label, count in sorted_counts:\n",
    "        print(f\"{label:20} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_window_distribution(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a37455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_upweight_majority_class(X_train, y_train, downsample_factor, majority_class):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    majority_class_indices = np.where(y_train == majority_class)[0]\n",
    "\n",
    "    X_majority_class = X_train[majority_class_indices]\n",
    "    y_majority_class = y_train[majority_class_indices]\n",
    "\n",
    "    print(f\"total number of rows on X for majority class {majority_class}: {len(X_majority_class)}\")\n",
    "    print(f\"total number of rows on y for majority class {majority_class}: {len(y_majority_class)}\")\n",
    "\n",
    "    number_of_majority_samples = len(X_majority_class)\n",
    "    number_of_samples_to_extract = number_of_majority_samples // downsample_factor\n",
    "\n",
    "    random_chosen_indices = np.random.choice(number_of_majority_samples, number_of_samples_to_extract, replace=False)\n",
    "\n",
    "    # downsampled_X = X_majority_class[random_chosen_indices]\n",
    "    # downsampled_y = y_majority_class[random_chosen_indices]\n",
    "\n",
    "    new_X_train = []\n",
    "    new_y_train = []\n",
    "\n",
    "    selected_majority_indices = majority_class_indices[random_chosen_indices]\n",
    "\n",
    "    for index in range(0, len(X_train)):\n",
    "        if index in selected_majority_indices:\n",
    "            new_X_train.append(X_train[index])\n",
    "            # new_sample_weights.append(sample_weights[index] * downsample_factor)\n",
    "            new_y_train.append(y_train[index])\n",
    "        elif index in majority_class_indices:\n",
    "            continue\n",
    "        else:\n",
    "            new_X_train.append(X_train[index])\n",
    "            # new_sample_weights.append(sample_weights[index])\n",
    "            new_y_train.append(y_train[index])\n",
    "    \n",
    "    return np.array(new_X_train), np.array(new_y_train)#, np.array(new_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a397409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.full(len(X_train), 1) # initialize weights array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39194c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_downsample_factors = {\n",
    "    'sleep': 12,\n",
    "    'sitting': 6,\n",
    "    # 'household-chores': 2,\n",
    "    # 'walking': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf694c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name, downsample_factor in class_downsample_factors.items():\n",
    "    new_X_train, new_y_train = downsample_upweight_majority_class(X_train, y_train, downsample_factor, class_name)\n",
    "    X_train = new_X_train\n",
    "    y_train = new_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "991afc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = new_X_train\n",
    "y_train = new_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_window_distribution(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ed865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "scaler = StandardScaler()\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_timesteps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83ffe7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])  # Flatten each window into a 1D array\n",
    "X_val_flat = X_val.reshape(-1, X_val.shape[-1])\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79ea5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train_flat).reshape(n_samples, n_timesteps, n_features)\n",
    "X_val_scaled = scaler.transform(X_val_flat).reshape(X_val.shape[0], n_timesteps, n_features)\n",
    "X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape[0], n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "007f51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote_input = X_train_scaled.reshape((X_train_scaled.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0b834d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_smote_input, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_window_distribution(y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a4eabf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled_ts = X_train_resampled.reshape((-1, n_timesteps, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fa06458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE LABELS\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train_resampled)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_val_cat = to_categorical(y_val_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "num_classes = y_train_cat.shape[1]  # Number of unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bcef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the LSTM model\n",
    "# model = Sequential([\n",
    "#     LSTM(128, input_shape=(X_resampled_ts.shape[1], X_resampled_ts.shape[2]), return_sequences=False),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     LSTM(128, input_shape=(X_resampled_ts.shape[1], X_resampled_ts.shape[2]), return_sequences=True),\n",
    "#     Dropout(0.3),\n",
    "#     LSTM(64, return_sequences=False), # Returns only the last output\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Conv1D(filters=64, kernel_size=3, activation='relu', padding='same',\n",
    "#            input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])),\n",
    "#     Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Dropout(0.3),\n",
    "#     LSTM(128, return_sequences=False),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Conv1D(filters=64, kernel_size=3, activation='relu', padding='same',\n",
    "#            input_shape=(X_resampled_ts.shape[1], X_resampled_ts.shape[2])),\n",
    "#     Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Dropout(0.3),\n",
    "#     Bidirectional(LSTM(128, return_sequences=False)),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12378100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Conv1D(filters=64, kernel_size=3, activation='relu', padding='same',\n",
    "#            input_shape=(X_resampled_ts.shape[1], X_resampled_ts.shape[2])),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Dropout(0.3),\n",
    "#     Bidirectional(LSTM(128, return_sequences=False)),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     Conv1D(filters=64, kernel_size=3, activation='relu', padding='same',\n",
    "#            input_shape=(X_resampled_ts.shape[1], X_resampled_ts.shape[2])),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "#     Dropout(0.3),\n",
    "#     Bidirectional(GRU(128, return_sequences=False)),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ec28c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    GRU(128, return_sequences=True, input_shape=(X_resampled_ts.shape[1], X_resampled_ts.shape[2])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    GRU(64),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42468161",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6164288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d86992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    X_resampled_ts, y_train_cat,\n",
    "    validation_data=(X_val_scaled, y_val_cat),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e6d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d3ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_labels = le.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "y_true_labels = le.inverse_transform(np.argmax(y_test_cat, axis=1))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
