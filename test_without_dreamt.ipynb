{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab9b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8c8824c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0fbad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train_data_without_dreamt.csv')\n",
    "val_df = pd.read_csv('./validation_data_without_dreamt.csv')\n",
    "test_df = pd.read_csv('./test_data_without_dreamt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0bf8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD SLIDING WINDOW\n",
    "# df - dataframe used\n",
    "# window_size - size of the sliding window, by default 11s if not mentioned otherwise\n",
    "# step_size - starting point for the current window given the previous, by default 5\n",
    "# feature_cols - features to be used in the sliding window\n",
    "def create_windows(dataset, window_size=11, step_size=5, feature_cols=['ACC_X', 'ACC_Y', 'ACC_Z']):\n",
    "    X = []\n",
    "    y = []\n",
    "    window = []\n",
    "\n",
    "    for person_id in dataset['PERSON_ID'].unique():\n",
    "        person_data = dataset[dataset['PERSON_ID'] == person_id]\n",
    "        feature_values = person_data[feature_cols].values\n",
    "        activity = person_data['ACTIVITY']\n",
    "\n",
    "        max_window_end = len(person_data)\n",
    "\n",
    "        for i in range(0, max_window_end - window_size, step_size):\n",
    "            window = feature_values[i:i+window_size]\n",
    "            window_label = activity[i:i+window_size].mode(dropna=False).iloc[0]\n",
    "\n",
    "            # Ensure the window is of the correct size\n",
    "            if len(window) != window_size:\n",
    "                continue  # Skip this window if it's the wrong shape\n",
    "\n",
    "            X.append(window)\n",
    "            y.append(window_label)\n",
    "\n",
    "    print(len(X))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f0a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "step_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f41f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_windows(train_df, window_size, step_size)\n",
    "X_val, y_val = create_windows(val_df, window_size, step_size)\n",
    "X_test, y_test = create_windows(test_df, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d7e6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_window_distribution(y_labels):\n",
    "    class_counts = Counter(y_labels)\n",
    "    sorted_counts = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Window count per class (descending):\")\n",
    "    for label, count in sorted_counts:\n",
    "        print(f\"{label:20} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_window_distribution(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "340250f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.full(len(X_train), 1) # initialize weights array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec44103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_upweight_majority_class(X_train, y_train, downsample_factor, majority_class, sample_weights):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    majority_class_indices = np.where(y_train == majority_class)[0]\n",
    "\n",
    "    X_majority_class = X_train[majority_class_indices]\n",
    "    y_majority_class = y_train[majority_class_indices]\n",
    "\n",
    "    print(f\"total number of rows on X for majority class {majority_class}: {len(X_majority_class)}\")\n",
    "    print(f\"total number of rows on y for majority class {majority_class}: {len(y_majority_class)}\")\n",
    "\n",
    "    number_of_majority_samples = len(X_majority_class)\n",
    "    number_of_samples_to_extract = number_of_majority_samples // downsample_factor\n",
    "\n",
    "    random_chosen_indices = np.random.choice(number_of_majority_samples, number_of_samples_to_extract, replace=False)\n",
    "\n",
    "    # downsampled_X = X_majority_class[random_chosen_indices]\n",
    "    # downsampled_y = y_majority_class[random_chosen_indices]\n",
    "\n",
    "    new_X_train = []\n",
    "    new_y_train = []\n",
    "    new_sample_weights = []\n",
    "\n",
    "    selected_majority_indices = majority_class_indices[random_chosen_indices]\n",
    "\n",
    "    for index in range(0, len(X_train)):\n",
    "        if index in selected_majority_indices:\n",
    "            new_X_train.append(X_train[index])\n",
    "            new_sample_weights.append(sample_weights[index] * downsample_factor)\n",
    "            new_y_train.append(y_train[index])\n",
    "        elif index in majority_class_indices:\n",
    "            continue\n",
    "        else:\n",
    "            new_X_train.append(X_train[index])\n",
    "            new_sample_weights.append(sample_weights[index])\n",
    "            new_y_train.append(y_train[index])\n",
    "    \n",
    "    return np.array(new_X_train), np.array(new_y_train), np.array(new_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee557072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA FOR THIS MODEL\n",
    "scaler = StandardScaler()\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_timesteps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f5ea931",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])  # Flatten each window into a 1D array\n",
    "X_val_flat = X_val.reshape(-1, X_val.shape[-1])\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "393c6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train_flat).reshape(n_samples, n_timesteps, n_features)\n",
    "X_val_scaled = scaler.transform(X_val_flat).reshape(X_val.shape[0], n_timesteps, n_features)\n",
    "X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape[0], n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2d23fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE LABELS\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_val_cat = to_categorical(y_val_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "num_classes = y_train_cat.shape[1]  # Number of unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0989453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Monitor validation loss\n",
    "    patience=5,            # Stop after 5 epochs of no improvement in val_loss\n",
    "    restore_best_weights=True, # Restore weights from the epoch with the best val_loss\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffb137da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b56b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    validation_data=(X_val_scaled, y_val_cat),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    # callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48357699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fd56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_labels = le.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "y_true_labels = le.inverse_transform(np.argmax(y_test_cat, axis=1))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
