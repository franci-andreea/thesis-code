{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548f145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Bidirectional, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a81cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def handle_empty_activity(activity):\n",
    "#     if pd.isna(activity):\n",
    "#         activity = 'NAN'\n",
    "#     return activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56585bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read capture24 dataset\n",
    "# fp = '/home/franci/licenta/datasets_archives/capture24/'\n",
    "# capture24_csv_files = glob.glob(fp + 'P*.csv')\n",
    "# capture24_csv_files.sort()\n",
    "\n",
    "# print(capture24_csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fdcfa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL_SET = 'label:WillettsSpecific2018'\n",
    "# activity_labels = 'annotation-label-dictionary.csv'\n",
    "# annotations_label_dict = pd.read_csv(fp + activity_labels, index_col='annotation', dtype='string')\n",
    "\n",
    "# person_id = 152\n",
    "# for f in capture24_csv_files:\n",
    "#     person_df = pd.read_csv(f, header=0, names=['TIMESTAMP', 'ACC_X', 'ACC_Y', 'ACC_Z', 'ANNOTATION'])\n",
    "#     person_df['ACTIVITY'] = annotations_label_dict[LABEL_SET].reindex(person_df['ANNOTATION']).to_numpy()\n",
    "#     person_df['ACTIVITY'] = person_df['ACTIVITY'].apply(lambda x: handle_empty_activity(x))\n",
    "#     person_df = person_df.drop('ANNOTATION', axis=1)\n",
    "#     person_df = person_df[person_df['ACTIVITY'] != 'NAN']\n",
    "#     person_df['PERSON_ID'] = person_id\n",
    "#     cols = person_df.columns.to_list()\n",
    "#     cols = cols[-1:] + cols[:-1]\n",
    "#     person_df = person_df[cols]\n",
    "#     person_df = person_df[::100]\n",
    "\n",
    "#     if person_id == 152:\n",
    "#         person_df.to_csv(f, mode='w+', index=False)\n",
    "#         print(\"Saved first file with header!\\n\")\n",
    "#     else:\n",
    "#         person_df.to_csv(f, mode='w+', index=False, header=False)\n",
    "\n",
    "#     print(person_id)\n",
    "#     person_id = person_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16061bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset & split \n",
    "capture24 = pd.read_csv('./all_capture24_original_timestamp.csv')\n",
    "capture24['TIMESTAMP'] = pd.to_datetime(capture24['TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc29b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df):\n",
    "    train_df = df[(df['PERSON_ID'] >= 152) & (df['PERSON_ID'] <= 257)].copy()\n",
    "    val_df = df[(df['PERSON_ID'] >= 258) & (df['PERSON_ID'] <= 287)].copy()\n",
    "    test_df = df[(df['PERSON_ID'] >= 288) & (df['PERSON_ID'] <= 302)].copy()\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17b83541",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = split_dataset(capture24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50a3362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD SLIDING WINDOW\n",
    "# df - dataframe used\n",
    "# window_size - size of the sliding window, by default 11s if not mentioned otherwise\n",
    "# step_size - starting point for the current window given the previous, by default 5\n",
    "# feature_cols - features to be used in the sliding window\n",
    "def create_windows(dataset, window_size=11, step_size=5, feature_cols=['ACC_X', 'ACC_Y', 'ACC_Z']):\n",
    "    X = []\n",
    "    y = []\n",
    "    window = []\n",
    "\n",
    "    for person_id in dataset['PERSON_ID'].unique():\n",
    "        person_data = dataset[dataset['PERSON_ID'] == person_id]\n",
    "        feature_values = person_data[feature_cols].values\n",
    "        activity = person_data['ACTIVITY']\n",
    "\n",
    "        max_window_end = len(person_data)\n",
    "\n",
    "        for i in range(0, max_window_end - window_size, step_size):\n",
    "            window = feature_values[i:i+window_size]\n",
    "            window_label = activity[i:i+window_size].mode(dropna=False).iloc[0]\n",
    "\n",
    "            # Ensure the window is of the correct size\n",
    "            if len(window) != window_size:\n",
    "                continue  # Skip this window if it's the wrong shape\n",
    "\n",
    "            X.append(window)\n",
    "            y.append(window_label)\n",
    "\n",
    "    print(len(X))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2060017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 180\n",
    "step_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_windows(train_df, window_size, step_size)\n",
    "X_val, y_val = create_windows(validation_df, window_size, step_size)\n",
    "X_test, y_test = create_windows(test_df, window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_time_train, y_time_train = create_windows(train_df, window_size, step_size, ['TIMESTAMP'])\n",
    "X_time_val, y_time_val = create_windows(validation_df, window_size, step_size, ['TIMESTAMP'])\n",
    "X_time_test, y_time_test = create_windows(test_df, window_size, step_size, ['TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87afaafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of windows per class to see the imbalance ratio among windows\n",
    "def print_window_distribution(y_labels):\n",
    "    class_counts = Counter(y_labels)\n",
    "    sorted_counts = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Window count per class (descending):\")\n",
    "    for label, count in sorted_counts:\n",
    "        print(f\"{label:20} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862159bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_window_distribution(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a25b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA\n",
    "scaler = StandardScaler()\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_timesteps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc36c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])  # Flatten each window into a 1D array\n",
    "X_val_flat = X_val.reshape(-1, X_val.shape[-1])\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9614f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train_flat).reshape(n_samples, n_timesteps, n_features)\n",
    "X_val_scaled = scaler.transform(X_val_flat).reshape(X_val.shape[0], n_timesteps, n_features)\n",
    "X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape[0], n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9984c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE LABELS\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_val_cat = to_categorical(y_val_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "num_classes = y_train_cat.shape[1]  # Number of unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a6b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main sequence input\n",
    "sequence_input = Input(shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]))\n",
    "x = GRU(128, return_sequences=True)(sequence_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = GRU(64)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Second input: time features\n",
    "time_input = Input(shape=(X_time_train.shape[1],))  # flat input\n",
    "\n",
    "# Combine both\n",
    "combined = Concatenate()([x, time_input])\n",
    "\n",
    "# Dense layers\n",
    "x = Dense(64, activation='relu')(combined)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model with two inputs\n",
    "model = Model(inputs=[sequence_input, time_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92f0de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f84833bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d74025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.fit(\n",
    "    [X_train_scaled, X_time_train],\n",
    "    y_train_cat,\n",
    "    validation_data=([X_val_scaled, X_time_val], y_val_cat), \n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c6f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "test_loss, test_acc = model.evaluate([X_test_scaled, X_time_test], y_test_cat, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_labels = le.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "y_true_labels = le.inverse_transform(np.argmax(y_test_cat, axis=1))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
