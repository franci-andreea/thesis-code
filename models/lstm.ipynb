{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bf14cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15d71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "train_df = pd.read_csv('../train_data.csv')\n",
    "validation_df = pd.read_csv('../validation_data.csv')\n",
    "test_df = pd.read_csv('../test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd247b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD SLIDING WINDOW\n",
    "# df - dataframe used\n",
    "# window_size - size of the sliding window, by default 11s if not mentioned otherwise\n",
    "# step_size - starting point for the current window given the previous, by default 5\n",
    "# feature_cols - features to be used in the sliding window\n",
    "def create_windows(dataset, window_size=11, step_size=5, feature_cols=['ACC_X', 'ACC_Y', 'ACC_Z']):\n",
    "    X = []\n",
    "    y = []\n",
    "    window = []\n",
    "\n",
    "    for person_id in dataset['PERSON_ID'].unique():\n",
    "        person_data = dataset[dataset['PERSON_ID'] == person_id]\n",
    "        feature_values = person_data[feature_cols].values\n",
    "        activity = person_data['ACTIVITY']\n",
    "\n",
    "        max_window_end = len(person_data)\n",
    "\n",
    "        for i in range(0, max_window_end - window_size, step_size):\n",
    "            window = feature_values[i:i+window_size]\n",
    "            window_label = activity[i:i+window_size].mode(dropna=False).iloc[0]\n",
    "\n",
    "            # Ensure the window is of the correct size\n",
    "            if len(window) != window_size:\n",
    "                continue  # Skip this window if it's the wrong shape\n",
    "\n",
    "            X.append(window)\n",
    "            y.append(window_label)\n",
    "\n",
    "    print(len(X))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f039b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = pd.read_csv('../train_data.csv')\n",
    "# validation_dataset = pd.read_csv('../validation_data.csv')\n",
    "# test_dataset = pd.read_csv('../test_data.csv')\n",
    "\n",
    "# min_count_train = min(train_dataset['ACTIVITY'].value_counts())\n",
    "# min_count_validation = min(validation_dataset['ACTIVITY'].value_counts())\n",
    "# min_count_test = min(test_dataset['ACTIVITY'].value_counts())\n",
    "\n",
    "# balanced_train_data = train_dataset.groupby('ACTIVITY').head(min_count_train).reset_index(drop=True)\n",
    "# balanced_validation_data = validation_dataset.groupby('ACTIVITY').head(min_count_validation).reset_index(drop=True)\n",
    "# balanced_test_data = test_dataset.groupby('ACTIVITY').head(min_count_test).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc6daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "step_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f682ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591698\n",
      "166621\n",
      "86205\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = create_windows(train_df, window_size=window_size, step_size=step_size)\n",
    "X_val, y_val = create_windows(validation_df, window_size=window_size, step_size=step_size)\n",
    "X_test, y_test = create_windows(test_df, window_size=window_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b878074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 3.1000000e+01  8.0000000e+00  5.5000000e+01]\n",
      "  [ 1.6000000e+01 -3.0000000e+00  5.6000000e+01]\n",
      "  [-5.8000000e+01  1.1000000e+01  2.0000000e+01]\n",
      "  ...\n",
      "  [-6.4000000e+01  3.0000000e+00 -8.0000000e+00]\n",
      "  [-6.4000000e+01  2.0000000e+00 -1.0000000e+01]\n",
      "  [-6.4000000e+01  2.0000000e+00 -9.0000000e+00]]\n",
      "\n",
      " [[-6.3000000e+01  3.0000000e+00 -1.6000000e+01]\n",
      "  [-6.1000000e+01  4.0000000e+00 -2.0000000e+01]\n",
      "  [-6.3000000e+01  1.0000000e+00 -1.7000000e+01]\n",
      "  ...\n",
      "  [-6.6000000e+01  3.0000000e+00 -6.0000000e+00]\n",
      "  [-6.5000000e+01  2.0000000e+00 -7.0000000e+00]\n",
      "  [-6.4000000e+01  3.0000000e+00 -7.0000000e+00]]\n",
      "\n",
      " [[-6.3000000e+01  3.0000000e+00 -2.0000000e+01]\n",
      "  [-6.2000000e+01  0.0000000e+00 -1.9000000e+01]\n",
      "  [-6.2000000e+01  4.0000000e+00 -2.1000000e+01]\n",
      "  ...\n",
      "  [-6.8000000e+01  7.0000000e+00 -2.0000000e+01]\n",
      "  [ 0.0000000e+00  2.0000000e+00  6.2000000e+01]\n",
      "  [-5.0000000e+00  8.0000000e+00  6.5000000e+01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.7969257e-02 -1.0859760e-01  1.0003531e+00]\n",
      "  [ 5.8094885e-02 -9.2813770e-02  1.0000253e+00]\n",
      "  [ 5.7969257e-02 -1.0859760e-01  1.0003531e+00]\n",
      "  ...\n",
      "  [ 5.8094885e-02 -9.2813770e-02  1.0000253e+00]\n",
      "  [ 5.8094885e-02 -9.2813770e-02  1.0000253e+00]\n",
      "  [ 7.3714300e-02 -1.0851913e-01  1.0000253e+00]]\n",
      "\n",
      " [[ 5.8094885e-02 -9.2813770e-02  9.8413810e-01]\n",
      "  [ 5.7969257e-02 -1.0859760e-01  1.0003531e+00]\n",
      "  [ 5.7969257e-02 -9.2892240e-02  1.0003531e+00]\n",
      "  ...\n",
      "  [ 5.7969257e-02 -9.2892240e-02  1.0003531e+00]\n",
      "  [ 5.7969257e-02 -9.2892240e-02  1.0003531e+00]\n",
      "  [ 5.7969257e-02 -1.0859760e-01  1.0003531e+00]]\n",
      "\n",
      " [[ 5.7969257e-02 -9.2892240e-02  1.0003531e+00]\n",
      "  [ 5.8094885e-02 -9.2813770e-02  1.0000253e+00]\n",
      "  [ 5.7969257e-02 -9.2892240e-02  1.0003531e+00]\n",
      "  ...\n",
      "  [ 5.7969257e-02 -9.2892240e-02  1.0003531e+00]\n",
      "  [ 5.7969257e-02 -9.2892240e-02  9.8446584e-01]\n",
      "  [ 5.7969257e-02 -9.2892240e-02  1.0003531e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "499b28cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sleep': 311264, 'sitting': 161927, 'household-chores': 28316, 'walking': 27028, 'vehicle': 16050, 'mixed-activity': 15950, 'standing': 14603, 'bicycling': 4730, 'manual-work': 3544, 'sports': 1793, 'writing': 453, 'jogging': 449, 'drinking': 448, 'eating pasta': 443, 'dribbling (basket ball)': 441, 'eating chips': 437, 'eating sandwich': 436, 'brushing teeth': 434, 'clapping': 433, 'kicking (soccer ball)': 433, 'eating soup': 431, 'playing catch (tennis ball)': 431, 'typing': 430, 'stairs': 424, 'folding clothes': 370}\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(y_train, return_counts=True)\n",
    "count_dict = {str(k): int(v) for k, v in zip(unique_values, counts)}\n",
    "count_dict_sorted = {k: v for k, v in sorted(count_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(count_dict_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a94d7717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bicycling': 5.003788583509514, 'brushing teeth': 54.53437788018433, 'clapping': 54.660323325635105, 'dribbling (basket ball)': 53.66875283446712, 'drinking': 52.83017857142857, 'eating chips': 54.16, 'eating pasta': 53.42645598194131, 'eating sandwich': 54.28422018348624, 'eating soup': 54.91396751740139, 'folding clothes': 63.967351351351354, 'household-chores': 0.835849696284786, 'jogging': 52.71251670378619, 'kicking (soccer ball)': 54.660323325635105, 'manual-work': 6.678306997742664, 'mixed-activity': 1.4838821316614421, 'playing catch (tennis ball)': 54.91396751740139, 'sitting': 0.14616413569077424, 'sleep': 0.07603808985298653, 'sports': 13.200178471834914, 'stairs': 55.82056603773585, 'standing': 1.6207573786208314, 'typing': 55.04167441860465, 'vehicle': 1.4746367601246106, 'walking': 0.8756815154654433, 'writing': 52.247064017660044}\n"
     ]
    }
   ],
   "source": [
    "weights = {}\n",
    "\n",
    "for class_name, class_weight in count_dict.items():\n",
    "    # weight_for_class_i = (total_number_of_rows_in_dataset) / (number_of_classes * total_number_of_rows_with_class_i)\n",
    "    weight_value = (np.size(y_train) / (len(count_dict) * class_weight))\n",
    "    # initialize weights dictionary in the format class_new_weight: weight_value \n",
    "    weights[class_name] = weight_value\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f54716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA FOR THIS MODEL\n",
    "scaler = StandardScaler()\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_timesteps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa319fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])  # Flatten each window into a 1D array\n",
    "X_val_flat = X_val.reshape(-1, X_val.shape[-1])\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b7a446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.1000000e+01  8.0000000e+00  5.5000000e+01]\n",
      " [ 1.6000000e+01 -3.0000000e+00  5.6000000e+01]\n",
      " [-5.8000000e+01  1.1000000e+01  2.0000000e+01]\n",
      " ...\n",
      " [ 5.7969257e-02 -9.2892240e-02  1.0003531e+00]\n",
      " [ 5.7969257e-02 -9.2892240e-02  9.8446584e-01]\n",
      " [ 5.7969257e-02 -9.2892240e-02  1.0003531e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc3d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train_flat).reshape(n_samples, n_timesteps, n_features)\n",
    "X_val_scaled = scaler.transform(X_val_flat).reshape(X_val.shape[0], n_timesteps, n_features)\n",
    "X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape[0], n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e145478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-3.141615    1.21467173 -0.73317939]\n",
      "  [-2.34705198  1.21467173 -0.47060262]\n",
      "  [-2.98270239  0.97440868 -1.83600183]\n",
      "  ...\n",
      "  [-2.61190632  0.55394835 -0.20802585]\n",
      "  [-3.24755673  0.67407987 -0.57563333]\n",
      "  [-3.3005276   0.61401411 -0.99575616]]\n",
      "\n",
      " [[-2.66487718  1.63513206 -1.67845577]\n",
      "  [-2.87676066  1.51500054 -1.83600183]\n",
      "  [-2.55893545  1.5750663  -1.99354789]\n",
      "  ...\n",
      "  [-3.77726541  0.67407987 -2.0985786 ]\n",
      "  [-2.61190632 -0.88762993  2.05013439]\n",
      "  [-2.98270239 -0.4671696  -0.57563333]]\n",
      "\n",
      " [[-3.56538194  1.87539511 -0.57563333]\n",
      "  [-2.71784805  2.11565815 -0.99575616]\n",
      "  [-3.141615    1.69519782 -1.10078687]\n",
      "  ...\n",
      "  [-2.77081892 -0.10677503  0.94731195]\n",
      "  [-3.19458586  0.43381683  1.05234266]\n",
      "  [-3.35349847  0.01335649 -0.2605412 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.21018153  0.04467495 -0.26907997]\n",
      "  [ 0.21018153  0.04467495 -0.26907997]\n",
      "  [ 0.21018153  0.04467495 -0.26907997]\n",
      "  ...\n",
      "  [ 0.21103031  0.04559894 -0.26903131]\n",
      "  [ 0.21103031  0.04465458 -0.26903131]\n",
      "  [ 0.21103031  0.04465458 -0.26903131]]\n",
      "\n",
      " [[ 0.21021089  0.04465458 -0.26903131]\n",
      "  [ 0.21021089  0.04559894 -0.26903131]\n",
      "  [ 0.21021089  0.04559894 -0.26903131]\n",
      "  ...\n",
      "  [ 0.21103031  0.04465458 -0.26903131]\n",
      "  [ 0.21103031  0.04465458 -0.26903131]\n",
      "  [ 0.21103031  0.04559894 -0.26903131]]\n",
      "\n",
      " [[ 0.21021089  0.04465458 -0.26987644]\n",
      "  [ 0.21021089  0.04465458 -0.26903131]\n",
      "  [ 0.21021089  0.04465458 -0.26903131]\n",
      "  ...\n",
      "  [ 0.21103031  0.04559894 -0.26903131]\n",
      "  [ 0.21103031  0.04559894 -0.26903131]\n",
      "  [ 0.21103031  0.04465458 -0.26987644]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfad15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE LABELS\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_val_cat = to_categorical(y_val_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "num_classes = y_train_cat.shape[1]  # Number of unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d3aa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f79f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748546320.123043   15947 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2253 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/home/franci/licenta/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# # build model\n",
    "# # Build the LSTM model\n",
    "# model = Sequential([\n",
    "#     LSTM(128, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=False),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749149151.771259   59728 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2222 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/home/franci/licenta/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential([\n",
    "#     LSTM(128, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True),\n",
    "#     Dropout(0.3),\n",
    "#     LSTM(64, return_sequences=False), # Returns only the last output\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bcd5a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franci/licenta/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0050e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca900e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1e7125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m9246/9246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 14ms/step - accuracy: 0.6523 - loss: 0.9492 - val_accuracy: 0.7340 - val_loss: 0.8044\n",
      "Epoch 2/100\n",
      "\u001b[1m9246/9246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 14ms/step - accuracy: 0.7712 - loss: 0.6686 - val_accuracy: 0.7610 - val_loss: 0.7372\n",
      "Epoch 3/100\n",
      "\u001b[1m9246/9246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 14ms/step - accuracy: 0.7900 - loss: 0.6190 - val_accuracy: 0.7621 - val_loss: 0.7477\n",
      "Epoch 4/100\n",
      "\u001b[1m9246/9246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 14ms/step - accuracy: 0.7986 - loss: 0.5976 - val_accuracy: 0.7690 - val_loss: 0.7305\n",
      "Epoch 5/100\n",
      "\u001b[1m9246/9246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 14ms/step - accuracy: 0.8036 - loss: 0.5841 - val_accuracy: 0.7676 - val_loss: 0.7499\n",
      "Epoch 6/100\n",
      "\u001b[1m9246/9246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 14ms/step - accuracy: 0.8057 - loss: 0.5752 - val_accuracy: 0.7709 - val_loss: 0.7556\n",
      "Epoch 7/100\n",
      "\u001b[1m9246/9246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 14ms/step - accuracy: 0.8097 - loss: 0.5648 - val_accuracy: 0.7713 - val_loss: 0.7625\n",
      "Epoch 8/100\n",
      "\u001b[1m9246/9246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 14ms/step - accuracy: 0.8132 - loss: 0.5542 - val_accuracy: 0.7746 - val_loss: 0.7343\n",
      "Epoch 9/100\n",
      "\u001b[1m9246/9246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 14ms/step - accuracy: 0.8143 - loss: 0.5489 - val_accuracy: 0.7752 - val_loss: 0.7723\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    validation_data=(X_val_scaled, y_val_cat),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    "    # class_weight=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b662881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7607 | Test loss: 0.7300\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2034040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2694/2694\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                  bicycling       0.26      0.38      0.31       713\n",
      "             brushing teeth       0.61      0.81      0.69       434\n",
      "                   clapping       0.85      0.75      0.80       433\n",
      "    dribbling (basket ball)       0.97      0.20      0.33       441\n",
      "                   drinking       0.44      0.54      0.49       448\n",
      "               eating chips       0.72      0.20      0.32       437\n",
      "               eating pasta       0.35      0.53      0.43       443\n",
      "            eating sandwich       0.31      0.25      0.28       436\n",
      "                eating soup       0.46      0.49      0.48       431\n",
      "            folding clothes       0.57      0.89      0.70       370\n",
      "           household-chores       0.51      0.59      0.54      5596\n",
      "                    jogging       0.95      0.89      0.92       449\n",
      "      kicking (soccer ball)       0.51      0.41      0.45       433\n",
      "                manual-work       0.23      0.01      0.01       680\n",
      "             mixed-activity       0.24      0.01      0.02      3120\n",
      "playing catch (tennis ball)       0.51      0.90      0.65       431\n",
      "                    sitting       0.69      0.77      0.72     17104\n",
      "                      sleep       0.95      0.98      0.96     42100\n",
      "                     sports       0.32      0.01      0.02       835\n",
      "                     stairs       0.82      0.12      0.21       424\n",
      "                   standing       0.69      0.15      0.25      2563\n",
      "                     typing       0.82      0.67      0.74       430\n",
      "                    vehicle       0.35      0.19      0.25      1836\n",
      "                    walking       0.41      0.62      0.49      5165\n",
      "                    writing       0.69      0.85      0.76       453\n",
      "\n",
      "                   accuracy                           0.76     86205\n",
      "                  macro avg       0.57      0.49      0.47     86205\n",
      "               weighted avg       0.75      0.76      0.74     86205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_labels = le.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "y_true_labels = le.inverse_transform(np.argmax(y_test_cat, axis=1))\n",
    "\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
