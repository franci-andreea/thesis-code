{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bf14cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a15d71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "train_df = pd.read_csv('../train_data.csv')\n",
    "validation_df = pd.read_csv('../validation_data.csv')\n",
    "test_df = pd.read_csv('../test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd247b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD SLIDING WINDOW\n",
    "# df - dataframe used\n",
    "# window_size - size of the sliding window, by default 11s if not mentioned otherwise\n",
    "# step_size - starting point for the current window given the previous, by default 5\n",
    "# feature_cols - features to be used in the sliding window\n",
    "def create_windows(dataset, window_size=11, step_size=5, feature_cols=['ACC_X', 'ACC_Y', 'ACC_Z']):\n",
    "    X = []\n",
    "    y = []\n",
    "    window = []\n",
    "\n",
    "    for person_id in dataset['PERSON_ID'].unique():\n",
    "        person_data = dataset[dataset['PERSON_ID'] == person_id]\n",
    "        feature_values = person_data[feature_cols].values\n",
    "        activity = person_data['ACTIVITY']\n",
    "\n",
    "        max_window_end = len(person_data)\n",
    "\n",
    "        for i in range(0, max_window_end - window_size, step_size):\n",
    "            window = feature_values[i:i+window_size]\n",
    "            window_label = activity[i:i+window_size].mode(dropna=False).iloc[0]\n",
    "\n",
    "            # Ensure the window is of the correct size\n",
    "            if len(window) != window_size:\n",
    "                continue  # Skip this window if it's the wrong shape\n",
    "\n",
    "            X.append(window)\n",
    "            y.append(window_label)\n",
    "\n",
    "    print(len(X))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f039b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = pd.read_csv('../train_data.csv')\n",
    "# validation_dataset = pd.read_csv('../validation_data.csv')\n",
    "# test_dataset = pd.read_csv('../test_data.csv')\n",
    "\n",
    "# min_count_train = min(train_dataset['ACTIVITY'].value_counts())\n",
    "# min_count_validation = min(validation_dataset['ACTIVITY'].value_counts())\n",
    "# min_count_test = min(test_dataset['ACTIVITY'].value_counts())\n",
    "\n",
    "# balanced_train_data = train_dataset.groupby('ACTIVITY').head(min_count_train).reset_index(drop=True)\n",
    "# balanced_validation_data = validation_dataset.groupby('ACTIVITY').head(min_count_validation).reset_index(drop=True)\n",
    "# balanced_test_data = test_dataset.groupby('ACTIVITY').head(min_count_test).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc6daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "step_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f682ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_windows(train_df, window_size=window_size, step_size=step_size)\n",
    "X_val, y_val = create_windows(validation_df, window_size=window_size, step_size=step_size)\n",
    "X_test, y_test = create_windows(test_df, window_size=window_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b878074",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, counts = np.unique(y_train, return_counts=True)\n",
    "count_dict = {str(k): int(v) for k, v in zip(unique_values, counts)}\n",
    "count_dict_sorted = {k: v for k, v in sorted(count_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(count_dict_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "\n",
    "for class_name, class_weight in count_dict.items():\n",
    "    # weight_for_class_i = (total_number_of_rows_in_dataset) / (number_of_classes * total_number_of_rows_with_class_i)\n",
    "    weight_value = (np.size(y_train) / (len(count_dict) * class_weight))\n",
    "    # initialize weights dictionary in the format class_new_weight: weight_value \n",
    "    weights[class_name] = weight_value\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f54716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE DATA FOR THIS MODEL\n",
    "scaler = StandardScaler()\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_timesteps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa319fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])  # Flatten each window into a 1D array\n",
    "X_val_flat = X_val.reshape(-1, X_val.shape[-1])\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc3d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train_flat).reshape(n_samples, n_timesteps, n_features)\n",
    "X_val_scaled = scaler.transform(X_val_flat).reshape(X_val.shape[0], n_timesteps, n_features)\n",
    "X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape[0], n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfad15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE LABELS\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_val_cat = to_categorical(y_val_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "num_classes = y_train_cat.shape[1]  # Number of unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d3aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f79f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build model\n",
    "# # Build the LSTM model\n",
    "# model = Sequential([\n",
    "#     LSTM(128, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=False),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#     LSTM(128, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=True),\n",
    "#     Dropout(0.3),\n",
    "#     LSTM(64, return_sequences=False), # Returns only the last output\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])),\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0050e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca900e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    validation_data=(X_val_scaled, y_val_cat),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping]\n",
    "    # class_weight=weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b662881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2034040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_labels = le.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "y_true_labels = le.inverse_transform(np.argmax(y_test_cat, axis=1))\n",
    "\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
