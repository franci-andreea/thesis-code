{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d368404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ca56e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4278e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e15dc39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "train_df = pd.read_csv('./train_data.csv')\n",
    "validation_df = pd.read_csv('./validation_data.csv')\n",
    "test_df = pd.read_csv('./test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e349f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row_distribution(df):\n",
    "    activity_counts = Counter(df['ACTIVITY'])\n",
    "    sorted_counts = sorted(activity_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Row count per class (descending):\")\n",
    "    for label, count in sorted_counts:\n",
    "        print(f\"{label:20} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94670d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_row_distribution(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f80ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD SLIDING WINDOW\n",
    "# df - dataframe used\n",
    "# window_size - size of the sliding window, by default 11s if not mentioned otherwise\n",
    "# step_size - starting point for the current window given the previous, by default 5\n",
    "# feature_cols - features to be used in the sliding window\n",
    "def create_windows(dataset, window_size=11, step_size=5, feature_cols=['ACC_X', 'ACC_Y', 'ACC_Z']):\n",
    "    X = []\n",
    "    y = []\n",
    "    window = []\n",
    "\n",
    "    for person_id in dataset['PERSON_ID'].unique():\n",
    "        person_data = dataset[dataset['PERSON_ID'] == person_id]\n",
    "        feature_values = person_data[feature_cols].values\n",
    "        activity = person_data['ACTIVITY']\n",
    "\n",
    "        max_window_end = len(person_data)\n",
    "\n",
    "        for i in range(0, max_window_end - window_size, step_size):\n",
    "            window = feature_values[i:i+window_size]\n",
    "            window_label = activity[i:i+window_size].mode(dropna=False).iloc[0]\n",
    "\n",
    "            # Ensure the window is of the correct size\n",
    "            if len(window) != window_size:\n",
    "                continue  # Skip this window if it's the wrong shape\n",
    "\n",
    "            X.append(window)\n",
    "            y.append(window_label)\n",
    "\n",
    "    print(len(X))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36dd9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 12\n",
    "step_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b933a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = create_windows(train_df, window_size=window_size, step_size=step_size)\n",
    "X_val, y_val = create_windows(validation_df, window_size=window_size, step_size=step_size)\n",
    "X_test, y_test = create_windows(test_df, window_size=window_size, step_size=step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86cf849c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of windows per class to see the imbalance ratio among windows\n",
    "def print_window_distribution(y_labels):\n",
    "    class_counts = Counter(y_labels)\n",
    "    sorted_counts = sorted(class_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"Window count per class (descending):\")\n",
    "    for label, count in sorted_counts:\n",
    "        print(f\"{label:20} {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_window_distribution(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a0f562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_upweight_majority_class(X_train, y_train, downsample_factor, majority_class, sample_weights):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    majority_class_indices = np.where(y_train == majority_class)[0]\n",
    "\n",
    "    X_majority_class = X_train[majority_class_indices]\n",
    "    y_majority_class = y_train[majority_class_indices]\n",
    "\n",
    "    print(f\"total number of rows on X for majority class {majority_class}: {len(X_majority_class)}\")\n",
    "    print(f\"total number of rows on y for majority class {majority_class}: {len(y_majority_class)}\")\n",
    "\n",
    "    number_of_majority_samples = len(X_majority_class)\n",
    "    number_of_samples_to_extract = number_of_majority_samples // downsample_factor\n",
    "\n",
    "    random_chosen_indices = np.random.choice(number_of_majority_samples, number_of_samples_to_extract, replace=False)\n",
    "\n",
    "    # downsampled_X = X_majority_class[random_chosen_indices]\n",
    "    # downsampled_y = y_majority_class[random_chosen_indices]\n",
    "\n",
    "    new_X_train = []\n",
    "    new_y_train = []\n",
    "    new_sample_weights = []\n",
    "\n",
    "    selected_majority_indices = majority_class_indices[random_chosen_indices]\n",
    "\n",
    "    for index in range(0, len(X_train)):\n",
    "        if index in selected_majority_indices:\n",
    "            new_X_train.append(X_train[index])\n",
    "            new_sample_weights.append(sample_weights[index] * downsample_factor)\n",
    "            new_y_train.append(y_train[index])\n",
    "        elif index in majority_class_indices:\n",
    "            continue\n",
    "        else:\n",
    "            new_X_train.append(X_train[index])\n",
    "            new_sample_weights.append(sample_weights[index])\n",
    "            new_y_train.append(y_train[index])\n",
    "    \n",
    "    return np.array(new_X_train), np.array(new_y_train), np.array(new_sample_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6097ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.full(len(X_train), 1) # initialize weights array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "518c1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_downsample_factors = {\n",
    "    'sleep': 20,\n",
    "    'sitting': 10,\n",
    "    'household-chores': 2,\n",
    "    'walking': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926214b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name, downsample_factor in class_downsample_factors.items():\n",
    "    new_X_train, new_y_train, sample_weights = downsample_upweight_majority_class(X_train, y_train, downsample_factor, class_name, sample_weights)\n",
    "    X_train = new_X_train\n",
    "    y_train = new_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12b1c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = new_X_train\n",
    "y_train = new_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ef60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_window_distribution(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aec4d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # z-score\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "n_timesteps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed5dd77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(-1, X_train.shape[-1])  # Flatten each window into a 1D array\n",
    "X_val_flat = X_val.reshape(-1, X_val.shape[-1])\n",
    "X_test_flat = X_test.reshape(-1, X_test.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09875e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.fit_transform(X_train_flat).reshape(n_samples, n_timesteps, n_features)\n",
    "X_val_scaled = scaler.transform(X_val_flat).reshape(X_val.shape[0], n_timesteps, n_features)\n",
    "X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape[0], n_timesteps, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e7e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE LABELS\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_cat = to_categorical(y_train_enc)\n",
    "y_val_cat = to_categorical(y_val_enc)\n",
    "y_test_cat = to_categorical(y_test_enc)\n",
    "\n",
    "num_classes = y_train_cat.shape[1]  # Number of unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334bfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute class weights\n",
    "# class_weights_array = class_weight.compute_class_weight(\n",
    "#     class_weight='balanced',\n",
    "#     classes=np.unique(y_train_enc),\n",
    "#     y=y_train_enc\n",
    "# )\n",
    "\n",
    "# # Convert to dictionary\n",
    "# class_weights = dict(enumerate(class_weights_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a556b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "# Build the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=False),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "225c1e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba1cda39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c3e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    validation_data=(X_val_scaled, y_val_cat),\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    "    # class_weight=class_weights\n",
    "    sample_weight=sample_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86df4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b583455",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_labels = le.inverse_transform(np.argmax(y_pred, axis=1))\n",
    "y_true_labels = le.inverse_transform(np.argmax(y_test_cat, axis=1))\n",
    "\n",
    "print(classification_report(y_true_labels, y_pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
